/**
 * Blog article: caching-strategies-redis-dotnet
 * Auto-generated by scripts/split-blog-articles.js. Do not edit the content here by hand if you run the split script again.
 */

export default {
  slug: "caching-strategies-redis-dotnet",
  title: "Caching Strategies: Redis, In-Memory, and Distributed in .NET",
  excerpt: "When and how to use in-memory, distributed, and response caching in .NET. Redis, IDistributedCache, and cache invalidation patterns.",
  date: "2024-05-20",
  topic: "Full-Stack",
  keywords: ["Caching Strategies: Redis, In-Memory, and Distributed in .NET", "Caching Strategies Redis Dotnet", "Caching Strategies Redis Dotnet best practices", "how to caching strategies redis dotnet", "caching strategies redis dotnet in .NET", "caching strategies redis dotnet guide", "caching strategies redis dotnet for enterprise", "caching strategies redis dotnet patterns", "when to use caching strategies redis dotnet", "caching strategies redis dotnet tutorial", "caching strategies redis dotnet examples", "caching strategies redis dotnet in C#", "caching strategies redis dotnet overview", "caching strategies redis dotnet implementation", "understanding caching strategies redis dotnet", "caching strategies redis dotnet for developers", "caching strategies redis dotnet checklist", "caching strategies redis dotnet tips", "caching strategies redis dotnet deep dive", "caching strategies redis dotnet comparison", "caching strategies redis dotnet vs alternatives", "caching strategies redis dotnet .NET Core", "caching strategies redis dotnet Azure", "caching strategies redis dotnet explained", "caching strategies redis dotnet when to use", "caching strategies redis dotnet enterprise", "caching strategies redis dotnet .NET", "what is caching strategies redis dotnet", "caching strategies redis dotnet summary", "caching strategies redis dotnet introduction", "caching strategies redis dotnet fundamentals", "caching strategies redis dotnet step by step", "caching strategies redis dotnet complete guide", "caching strategies redis dotnet for beginners", "caching strategies redis dotnet advanced", "caching strategies redis dotnet production", "caching strategies redis dotnet real world", "caching strategies redis dotnet example code", "caching strategies redis dotnet C# example", "caching strategies redis dotnet .NET example", "learn caching strategies redis dotnet", "caching strategies redis dotnet learn", "caching strategies redis dotnet reference", "caching strategies redis dotnet cheat sheet", "caching strategies redis dotnet pitfalls", "caching strategies redis dotnet common mistakes", "caching strategies redis dotnet performance", "caching strategies redis dotnet optimization", "caching strategies redis dotnet security", "caching strategies redis dotnet testing", "caching strategies redis dotnet unit test", "caching strategies redis dotnet integration", "caching strategies redis dotnet migration", "caching strategies redis dotnet from scratch", "caching strategies redis dotnet 2024", "caching strategies redis dotnet 2025", "best caching strategies redis dotnet", "caching strategies redis dotnet best", "pro caching strategies redis dotnet", "caching strategies redis dotnet expert", "caching strategies redis dotnet consultant", "caching strategies redis dotnet services", "caching strategies redis dotnet course", "caching strategies redis dotnet workshop", "caching strategies redis dotnet webinar", "caching strategies redis dotnet blog", "caching strategies redis dotnet article", "caching strategies redis dotnet post", "why caching strategies redis dotnet", "when caching strategies redis dotnet", "where caching strategies redis dotnet", "caching strategies redis dotnet in .NET 6", "caching strategies redis dotnet in .NET 7", "caching strategies redis dotnet in .NET 8", "caching strategies redis dotnet for C#", "caching strategies redis dotnet for Angular", "caching strategies redis dotnet for Vue", "caching strategies redis dotnet for React", "caching strategies redis dotnet for Azure", "caching strategies redis dotnet for microservices", "caching strategies redis dotnet for API", "caching strategies redis dotnet for database", "caching strategies redis dotnet for testing", "caching strategies redis dotnet for DevOps", "caching strategies redis dotnet for senior developers", "caching strategies redis dotnet for team", "caching strategies redis dotnet for production", "caching strategies redis dotnet for scale", "caching strategies redis dotnet for refactoring", "caching strategies redis dotnet for enterprise applications", "caching strategies redis dotnet for startup", "caching strategies redis dotnet in 2024", "caching strategies redis dotnet in 2025", "caching strategies redis dotnet in 2026", "caching strategies redis dotnet code sample", "caching strategies redis dotnet code example", "caching strategies redis dotnet sample code", "caching strategies redis dotnet full example", "caching strategies redis dotnet working example", "caching strategies redis dotnet practical caching strategies redis dotnet", "caching strategies redis dotnet real world example", "caching strategies redis dotnet use case", "caching strategies redis dotnet use cases", "caching strategies redis dotnet scenario", "caching strategies redis dotnet scenarios", "caching strategies redis dotnet pattern", "caching strategies redis dotnet approach", "caching strategies redis dotnet approaches", "caching strategies redis dotnet strategy", "caching strategies redis dotnet strategies", "caching strategies redis dotnet technique", "caching strategies redis dotnet techniques", "caching strategies redis dotnet method", "caching strategies redis dotnet methods", "caching strategies redis dotnet solution", "caching strategies redis dotnet solutions", "caching strategies redis dotnet implementation guide", "caching strategies redis dotnet getting started", "caching strategies redis dotnet quick start", "caching strategies redis dotnet overview guide", "caching strategies redis dotnet comprehensive guide", "caching strategies redis dotnet detailed guide", "caching strategies redis dotnet practical guide", "caching strategies redis dotnet developer guide", "caching strategies redis dotnet engineer guide", "caching strategies redis dotnet architect guide", "caching strategies redis dotnet for architects", "caching strategies redis dotnet for backend", "caching strategies redis dotnet for tech leads", "caching strategies redis dotnet for senior devs", "benefits of caching strategies redis dotnet", "advantages of caching strategies redis dotnet", "alternatives to caching strategies redis dotnet", "compared to caching strategies redis dotnet", "intro to caching strategies redis dotnet", "basics of caching strategies redis dotnet", "caching strategies redis dotnet tips and tricks", "caching strategies redis dotnet production-ready", "caching strategies redis dotnet enterprise-grade", "caching strategies redis dotnet with Docker", "caching strategies redis dotnet with Kubernetes", "caching strategies redis dotnet in ASP.NET Core", "caching strategies redis dotnet with Entity Framework", "caching strategies redis dotnet with EF Core", "caching strategies redis dotnet modern", "caching strategies redis dotnet updated", "caching strategies redis dotnet latest", "caching strategies redis dotnet walkthrough", "caching strategies redis dotnet hands-on", "caching strategies redis dotnet practical examples", "caching strategies redis dotnet real-world examples", "caching strategies redis dotnet common pitfalls", "caching strategies redis dotnet gotchas", "caching strategies redis dotnet FAQ", "caching strategies redis dotnet FAQs", "caching strategies redis dotnet Q&A", "caching strategies redis dotnet interview questions", "caching strategies redis dotnet interview", "caching strategies redis dotnet certification", "caching strategies redis dotnet training", "caching strategies redis dotnet video", "caching strategies redis dotnet series", "caching strategies redis dotnet part 1", "caching strategies redis dotnet core concepts", "caching strategies redis dotnet key concepts", "caching strategies redis dotnet recap", "caching strategies redis dotnet takeaways", "caching strategies redis dotnet conclusion", "caching strategies redis dotnet next steps", "caching strategies redis dotnet further reading", "caching strategies redis dotnet resources", "caching strategies redis dotnet tools", "caching strategies redis dotnet libraries", "caching strategies redis dotnet frameworks", "caching strategies redis dotnet NuGet", "caching strategies redis dotnet package", "caching strategies redis dotnet GitHub", "caching strategies redis dotnet open source", "caching strategies redis dotnet community", "caching strategies redis dotnet Microsoft docs", "caching strategies redis dotnet documentation", "caching strategies redis dotnet official guide", "caching strategies redis dotnet official tutorial", "caching strategies redis with .NET Core", "caching strategies redis dotnet ASP.NET Core", "Caching", "Caching guide", "Caching tutorial", "Caching best practices", "Caching in .NET", "Caching in C#", "Caching for developers", "Caching examples", "Caching patterns", "Caching overview", "Caching introduction", "Caching deep dive", "Caching explained", "Caching how to", "Caching what is"],
  relatedServices: ["full-stack-development","azure-cloud-architecture"],
  relatedProjects: ["bat-inhouse-app"],
  relatedArticleSlugs: ["database-optimization-entity-framework","azure-microservices-best-practices"],
  author: "Waqas Ahmad",
  content: `## Introduction

This guidance is relevant when the topic of this article applies to your system or design choices; it breaks down when constraints or context differ. I've applied it in real projects and refined the takeaways over time (as of 2026).

**Caching** is one of the most effective ways to improve application performance. Instead of hitting the database or external service on every request, you store the result in a fast storage layer and serve it from there. This reduces latency and load on your backend systems.

In .NET, you have several caching options: **IMemoryCache** for in-process caching, **IDistributedCache** for shared caching across instances (Redis, SQL Server), and **response caching** for HTTP responses. This article covers when to use each, common patterns like cache-aside and write-through, invalidation strategies, and how to avoid common pitfalls.

## Topics covered

- [Decision Context](#decision-context)
- [Types of caching](#types-of-caching)
- [IMemoryCache: in-process caching](#imemorycache-in-process-caching)
- [IDistributedCache: shared caching](#idistributedcache-shared-caching)
- [Redis: the go-to distributed cache](#redis-the-go-to-distributed-cache)
- [Caching patterns](#caching-patterns)
- [Cache invalidation](#cache-invalidation)
- [Response caching](#response-caching)
- [Enterprise best practices](#enterprise-best-practices)
- [Common issues](#common-issues)
- [Summary](#summary)
- [Position & Rationale](#position--rationale)
- [Trade-Offs & Failure Modes](#trade-offs--failure-modes)
- [What Most Guides Miss](#what-most-guides-miss)
- [Decision Framework](#decision-framework)
- [Key Takeaways](#key-takeaways)
- [When I Would Use This Again — and When I Wouldn't](#when-i-would-use-this-again--and-when-i-wouldnt)
- [Frequently Asked Questions](#frequently-asked-questions)

## Decision Context

- **System scale:** Single instance to many; read-heavy or mixed read/write workloads. Applies when you want to reduce database or backend load and improve latency.
- **Team size:** One developer to a platform team; someone must own cache topology, invalidation, and failure behaviour. Works when dev and ops agree on what can be cached and how to invalidate.
- **Time / budget pressure:** Fits when you have time to design keys, TTLs, and invalidation; breaks down when data is always fresh or consistency is strict and you can’t tolerate staleness.
- **Technical constraints:** .NET (IMemoryCache, IDistributedCache); Redis or compatible store for distributed; optionally Azure Cache for Redis. Assumes you can run or consume a cache service.
- **Non-goals:** This article does not optimise for application-level only (no cache), or for CDN/edge-only; it focuses on in-process and distributed caching in .NET with Redis.

## Types of caching

| Type | Where | Use case |
|------|-------|----------|
| **In-memory (IMemoryCache)** | Single process | Single instance apps, non-critical data |
| **Distributed (Redis)** | Shared across instances | Multi-instance apps, shared state |
| **Response caching** | HTTP layer | Static or rarely-changing responses |
| **Output caching (.NET 7+)** | Server-side | Full page or endpoint caching |

## IMemoryCache: in-process caching

\`IMemoryCache\` stores data in the application's memory. It is fast (no network), but the cache is lost on restart and not shared across instances.

**When to use:**
- Single-instance applications
- Data that can be regenerated
- Short-lived caching (e.g. lookup data)

**Setup:**

\`\`\`csharp
// Program.cs
builder.Services.AddMemoryCache();
\`\`\`

**Usage:**

\`\`\`csharp
public class ProductService
{
    private readonly IMemoryCache _cache;
    private readonly IProductRepository _repository;

    public ProductService(IMemoryCache cache, IProductRepository repository)
    {
        _cache = cache;
        _repository = repository;
    }

    public async Task<Product?> GetProductAsync(string id)
    {
        var cacheKey = $"product:{id}";
        
        if (_cache.TryGetValue(cacheKey, out Product? cached))
        {
            return cached;
        }

        var product = await _repository.GetByIdAsync(id);
        
        if (product != null)
        {
            var options = new MemoryCacheEntryOptions()
                .SetAbsoluteExpiration(TimeSpan.FromMinutes(10))
                .SetSlidingExpiration(TimeSpan.FromMinutes(2));
                
            _cache.Set(cacheKey, product, options);
        }

        return product;
    }
}
\`\`\`

**Expiration options:**

| Option | Description |
|--------|-------------|
| \`AbsoluteExpiration\` | Fixed time when entry expires |
| \`AbsoluteExpirationRelativeToNow\` | Expires after X time from now |
| \`SlidingExpiration\` | Resets on each access; expires if not accessed |

## IDistributedCache: shared caching

\`IDistributedCache\` is an abstraction over distributed caches like Redis, SQL Server, or NCache. Data is shared across all application instances.

**When to use:**
- Multi-instance deployments (load-balanced)
- Data that must be consistent across instances
- Session state, shopping carts, user preferences

**Setup with Redis:**

\`\`\`csharp
// Program.cs
builder.Services.AddStackExchangeRedisCache(options =>
{
    options.Configuration = builder.Configuration.GetConnectionString("Redis");
    options.InstanceName = "myapp:";
});
\`\`\`

**Usage:**

\`\`\`csharp
public class OrderService
{
    private readonly IDistributedCache _cache;
    private readonly IOrderRepository _repository;

    public OrderService(IDistributedCache cache, IOrderRepository repository)
    {
        _cache = cache;
        _repository = repository;
    }

    public async Task<Order?> GetOrderAsync(string id)
    {
        var cacheKey = $"order:{id}";
        
        var cached = await _cache.GetStringAsync(cacheKey);
        if (cached != null)
        {
            return JsonSerializer.Deserialize<Order>(cached);
        }

        var order = await _repository.GetByIdAsync(id);
        
        if (order != null)
        {
            var options = new DistributedCacheEntryOptions
            {
                AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(10)
            };
            
            await _cache.SetStringAsync(
                cacheKey, 
                JsonSerializer.Serialize(order), 
                options);
        }

        return order;
    }

    public async Task InvalidateOrderAsync(string id)
    {
        await _cache.RemoveAsync($"order:{id}");
    }
}
\`\`\`

## Redis: the go-to distributed cache

**Redis** is an in-memory data store that supports strings, hashes, lists, sets, and more. It is the most common distributed cache for .NET applications.

**Azure Cache for Redis** is the managed Redis offering on Azure:
- Scales automatically
- High availability with replicas
- Geo-replication for global apps
- Private endpoints for security

**Connection string format:**

\`\`\`
myredis.redis.cache.windows.net:6380,password=...,ssl=True,abortConnect=False
\`\`\`

**Redis data types for caching:**

| Type | Use case |
|------|----------|
| **String** | Simple key-value (most common) |
| **Hash** | Object with multiple fields |
| **List** | Queues, recent items |
| **Set** | Unique collections, tags |
| **Sorted Set** | Leaderboards, rankings |

## Caching patterns

### Cache-aside (lazy loading)

The application checks the cache first. On a miss, it loads from the database and populates the cache.

\`\`\`csharp
public async Task<T?> GetOrSetAsync<T>(string key, Func<Task<T?>> factory, TimeSpan ttl)
{
    var cached = await _cache.GetStringAsync(key);
    if (cached != null)
    {
        return JsonSerializer.Deserialize<T>(cached);
    }

    var data = await factory();
    if (data != null)
    {
        await _cache.SetStringAsync(
            key, 
            JsonSerializer.Serialize(data),
            new DistributedCacheEntryOptions { AbsoluteExpirationRelativeToNow = ttl });
    }

    return data;
}

// Usage
var order = await GetOrSetAsync(
    $"order:{id}",
    () => _repository.GetByIdAsync(id),
    TimeSpan.FromMinutes(10));
\`\`\`

### Write-through

On write, update both the cache and the database together.

\`\`\`csharp
public async Task UpdateOrderAsync(Order order)
{
    // Update database
    await _repository.UpdateAsync(order);
    
    // Update cache
    await _cache.SetStringAsync(
        $"order:{order.Id}",
        JsonSerializer.Serialize(order),
        new DistributedCacheEntryOptions { AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(10) });
}
\`\`\`

### Write-behind (async)

Write to cache immediately; persist to database asynchronously. Use for high-write scenarios where slight delay is acceptable.

## Cache invalidation

**Invalidation** ensures the cache reflects the current state of the data. Options:

| Strategy | Description | When to use |
|----------|-------------|-------------|
| **Time-based (TTL)** | Entry expires after X time | Data that can be slightly stale |
| **Explicit invalidation** | Remove entry on update/delete | Critical data, exact consistency |
| **Event-based** | Pub/sub triggers invalidation | Multi-instance, complex dependencies |

**Explicit invalidation:**

\`\`\`csharp
public async Task DeleteOrderAsync(string id)
{
    await _repository.DeleteAsync(id);
    await _cache.RemoveAsync($"order:{id}");
}
\`\`\`

**Event-based with Redis pub/sub:**

\`\`\`csharp
// Publisher (on update)
await _subscriber.PublishAsync("cache:invalidate", $"order:{id}");

// Subscriber (all instances)
_subscriber.Subscribe("cache:invalidate", (channel, message) =>
{
    _cache.Remove(message);
});
\`\`\`

## Response caching

**Response caching** caches HTTP responses. The client or a CDN can serve cached responses without hitting your server.

\`\`\`csharp
// Program.cs
builder.Services.AddResponseCaching();

var app = builder.Build();
app.UseResponseCaching();

// Controller
[HttpGet("{id}")]
[ResponseCache(Duration = 60, VaryByQueryKeys = new[] { "id" })]
public async Task<ActionResult<Product>> GetProduct(string id)
{
    return Ok(await _service.GetProductAsync(id));
}
\`\`\`

**Output caching (.NET 7+):**

\`\`\`csharp
builder.Services.AddOutputCache();

app.UseOutputCache();

app.MapGet("/products/{id}", async (string id, IProductService service) =>
{
    return await service.GetProductAsync(id);
}).CacheOutput(policy => policy.Expire(TimeSpan.FromMinutes(5)));
\`\`\`

## Enterprise best practices

**1. Use distributed cache for multi-instance.** If you have more than one instance, use Redis. In-memory cache will be inconsistent.

**2. Set appropriate TTLs.** Short for frequently-changing data; longer for stable data. Balance freshness vs hit rate.

**3. Use cache-aside by default.** It is simple and works for most read-heavy scenarios.

**4. Invalidate explicitly on writes.** Do not rely only on TTL for critical data. Remove or update cache entries on write.

**5. Handle cache failures gracefully.** If Redis is down, fall back to database. Do not let cache failures break your app.

\`\`\`csharp
try
{
    var cached = await _cache.GetStringAsync(key);
    if (cached != null) return JsonSerializer.Deserialize<Order>(cached);
}
catch (Exception ex)
{
    _logger.LogWarning(ex, "Cache read failed for {Key}", key);
}

// Fall back to database
return await _repository.GetByIdAsync(id);
\`\`\`

**6. Monitor cache metrics.** Track hit rate, miss rate, latency, and memory usage. Low hit rate means your caching strategy needs adjustment.

**7. Use consistent key naming.** Format: \`{entity}:{id}\` or \`{service}:{entity}:{id}\`. Makes debugging and invalidation easier.

**8. Avoid large objects.** Serialisation cost increases with size. Consider caching IDs and fetching details separately.

## Common issues

| Issue | Symptom | Fix |
|-------|---------|-----|
| **Stale data** | Users see outdated info | Invalidate on write; reduce TTL |
| **Cache stampede** | DB hammered on expiry | Use locking or stale-while-revalidate |
| **Memory pressure** | Out of memory errors | Set size limits; use eviction (LRU) |
| **Serialisation errors** | Exceptions on read/write | Use consistent serialiser; handle nulls |
| **Redis connection issues** | Timeouts, failures | Use connection pooling; handle exceptions |
| **Inconsistent keys** | Partial invalidation | Use consistent key format; document patterns |

**Cache stampede prevention:**

\`\`\`csharp
private static readonly SemaphoreSlim _lock = new(1, 1);

public async Task<Order?> GetOrderWithLockAsync(string id)
{
    var cacheKey = $"order:{id}";
    var cached = await _cache.GetStringAsync(cacheKey);
    if (cached != null) return JsonSerializer.Deserialize<Order>(cached);

    await _lock.WaitAsync();
    try
    {
        // Double-check after acquiring lock
        cached = await _cache.GetStringAsync(cacheKey);
        if (cached != null) return JsonSerializer.Deserialize<Order>(cached);

        var order = await _repository.GetByIdAsync(id);
        if (order != null)
        {
            await _cache.SetStringAsync(cacheKey, JsonSerializer.Serialize(order),
                new DistributedCacheEntryOptions { AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(10) });
        }
        return order;
    }
    finally
    {
        _lock.Release();
    }
}
\`\`\`

## Summary

Caching improves performance and reduces load on your backend. Use \`IMemoryCache\` for single-instance apps, \`IDistributedCache\` (Redis) for multi-instance deployments. Apply cache-aside for reads, invalidate on writes, and handle failures gracefully.

## Position & Rationale

I use **IMemoryCache** when the app runs as a single instance or when the data is process-local and doesn’t need to be shared (e.g. per-request or per-instance lookups). I use **Redis** (IDistributedCache) when there are multiple instances or when cache must survive restarts and be consistent across replicas. I avoid caching when data is always fresh or when invalidation is unclear—stale cache is worse than no cache. I prefer **cache-aside** over write-through for most read-heavy cases because it’s simpler and invalidation on write is explicit; I use write-through only when I need the cache to always reflect the source of truth and can afford the write path complexity. I always design cache keys and TTLs up front; ad-hoc keys lead to unbounded growth and hard-to-debug invalidation.

## Trade-Offs & Failure Modes

**In-memory** sacrifices consistency across instances and persistence across restarts; you gain simplicity and no network dependency. **Distributed (Redis)** adds network latency and a dependency; you gain shared state and persistence. **Caching** in general sacrifices freshness for speed; wrong TTL or missed invalidation causes stale data. Failure modes: cache stampede on expiry (many requests hitting the backend at once); Redis down and no fallback (app should degrade to backend); over-caching and never invalidating (stale reads); caching non-idempotent or user-specific data in a shared key (security or correctness bugs).

## What Most Guides Miss

Most guides show “how to use IMemoryCache and Redis” but don’t stress **invalidation** as the hard part. Deciding when to remove or update cache (on write, on event, on TTL) and doing it correctly across instances (pub/sub, or accept per-instance delay) is where things go wrong. Another gap: **failure behaviour**—what happens when Redis is unavailable? You need a fallback (e.g. direct to database) and circuit-breaker or timeout so one slow Redis doesn’t take down the app. **Key design** is underplayed: keys that are too broad cause over-invalidation; keys that are too fine cause low hit rate and memory growth.

## Decision Framework

- **If single instance and data can be process-local** → IMemoryCache; keep it simple.
- **If multiple instances or cache must survive restarts** → Redis (IDistributedCache); use a shared connection.
- **If read-heavy and writes are infrequent** → Cache-aside; invalidate (remove or update) on write.
- **If you need cache and source always in sync on write** → Write-through; accept write latency.
- **For production** → Define key schema and TTLs; handle Redis failure (fallback, timeouts); monitor hit rate and evictions.

## Key Takeaways

- **IMemoryCache** for single instance; **Redis** for multi-instance or shared, persistent cache.
- **Cache-aside** with invalidation on write is the default; write-through only when you need strict consistency.
- Design **keys and TTLs** up front; avoid ad-hoc keys and unbounded growth.
- **Handle Redis failure**: fallback to backend, timeouts, and monitoring so the app degrades gracefully.
- Invalidation is the hard part—get it right or accept staleness explicitly.

## When I Would Use This Again — and When I Wouldn't

I’d use **IMemoryCache** again for single-instance apps and for data that doesn’t need to be shared. I’d use **Redis** again for multi-instance .NET apps and when cache must survive restarts. I wouldn’t add caching when the data is always fresh or when I can’t define a clear invalidation strategy—stale cache leads to bugs and confusion. I also wouldn’t cache without a fallback when Redis is down; the app must still work (slower) without the cache.

## Frequently Asked Questions

### What is cache-aside?

**Cache-aside** (lazy loading): application checks cache first. On miss, loads from database and stores in cache. Most common pattern.

### What is distributed cache?

**Distributed cache** is shared across app instances (e.g. Redis). Use when you have multiple instances or need consistent cache.

### When should I use Redis vs IMemoryCache?

Use \`IMemoryCache\` for single instance. Use Redis (\`IDistributedCache\`) for multi-instance deployments or when cache must survive restarts.

### How do I invalidate cache on data change?

Remove or update the cache entry on write: \`await _cache.RemoveAsync(key)\`. For multi-instance, use pub/sub or messaging.

### What is cache stampede?

When many requests miss at the same time (e.g. on expiry) and all hit the database. Prevent with locking or stale-while-revalidate.

### What TTL should I use?

Depends on data freshness requirements. Minutes for frequently-changing data; hours for stable data. Monitor and adjust.

### How do I handle Redis failures?

Wrap cache calls in try-catch. Fall back to database if cache is unavailable. Log warnings for monitoring.

### What is write-through caching?

Update both cache and database on write. Ensures cache is always fresh but adds latency to writes.

### What is response caching?

Caching HTTP responses at the server or CDN level. Use \`[ResponseCache]\` attribute in ASP.NET Core.

### How do I monitor cache performance?

Track hit rate, miss rate, latency, and evictions. Use Redis INFO command or Azure Monitor for Azure Cache for Redis.

### What serialisation format should I use?

JSON is simple and debuggable. For performance-critical paths, consider MessagePack or protobuf.

### Can I cache null values?

Yes, to prevent repeated database lookups for non-existent keys. Use a sentinel value or separate "not found" cache.

### How do I cache collections?

Cache the list of IDs, then cache individual items. Invalidate the list when items are added/removed.

### What is Azure Cache for Redis?

Managed Redis on Azure with automatic scaling, high availability, and geo-replication. Common choice for .NET apps on Azure.

### How do I warm the cache on startup?

Load frequently-accessed data at application startup. Use \`IHostedService\` or startup hooks to pre-populate cache.`,
  faqs: [
  {
    "question": "What is cache-aside?",
    "answer": "Cache-aside (lazy loading): app checks cache first, on miss loads from DB and stores in cache. Most common pattern."
  },
  {
    "question": "What is distributed cache?",
    "answer": "Shared cache across app instances (e.g. Redis). Use for multi-instance deployments or consistent cache."
  },
  {
    "question": "When use Redis vs IMemoryCache?",
    "answer": "IMemoryCache for single instance. Redis (IDistributedCache) for multi-instance or cache that survives restarts."
  },
  {
    "question": "How to invalidate on change?",
    "answer": "Remove or update cache entry on write. For multi-instance, use pub/sub or messaging."
  },
  {
    "question": "What is cache stampede?",
    "answer": "Many requests miss at once and hit DB. Prevent with locking or stale-while-revalidate."
  },
  {
    "question": "What TTL should I use?",
    "answer": "Depends on freshness needs. Minutes for changing data; hours for stable data. Monitor and adjust."
  },
  {
    "question": "How handle Redis failures?",
    "answer": "Wrap in try-catch, fall back to database. Log warnings for monitoring."
  },
  {
    "question": "What is write-through?",
    "answer": "Update both cache and database on write. Cache is always fresh but adds write latency."
  },
  {
    "question": "What is response caching?",
    "answer": "Caching HTTP responses at server or CDN. Use [ResponseCache] attribute in ASP.NET Core."
  },
  {
    "question": "How monitor cache performance?",
    "answer": "Track hit rate, miss rate, latency. Use Redis INFO or Azure Monitor."
  },
  {
    "question": "What serialisation format?",
    "answer": "JSON is simple. For performance, consider MessagePack or protobuf."
  },
  {
    "question": "Can I cache null values?",
    "answer": "Yes, prevents repeated lookups for non-existent keys. Use sentinel value."
  },
  {
    "question": "How cache collections?",
    "answer": "Cache list of IDs, then individual items. Invalidate list on add/remove."
  },
  {
    "question": "What is Azure Cache for Redis?",
    "answer": "Managed Redis on Azure with scaling, HA, and geo-replication."
  },
  {
    "question": "How warm cache on startup?",
    "answer": "Load frequent data at startup using IHostedService or startup hooks."
  }
]
}
